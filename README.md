# Memory-efficient FFN/MoE Inference by Approximation
A sparse and retraining-free FFN/MoE inference algorithm for large language model (LLM)
